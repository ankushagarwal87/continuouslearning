{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Anatomy of a neural network\n",
    "\n",
    "    Layers, which are combined into a network (or model)\n",
    "    The input data and corresponding targets\n",
    "    The loss function, which defines the feedback signal used for learning\n",
    "    The optimizer, which determines how learning proceeds\n",
    "    \n",
    "<img src=\"03fig01.jpg\">\n",
    "\n",
    "#### 3.1.1. Layers: the building blocks of deep learning\n",
    "    A layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors. Some layers are stateless, but more frequently layers have a state: the layer’s weights, one or several tensors learned with stochastic gradient descent, which together contain the network’s knowledge.\n",
    "    \n",
    "#### 3.1.2. Models: networks of layers\n",
    "#### 3.1.3. Loss functions and optimizers: keys to configuring the learning process\n",
    "    \n",
    "    Loss function (objective function)— The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    "    Optimizer— Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
    "    \n",
    "    Use binary crossentropy for a two-class classification problem, categorical crossentropy for a many-class classification problem, mean-squared error for a regression problem, connectionist temporal classification (CTC) for a sequence-learning problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Introduction to Keras\n",
    "#### 3.2.1. Keras, TensorFlow, Theano, and CNTK\n",
    "#### 3.2.2. Developing with Keras: a quick overview\n",
    "    \n",
    "    Define your training data: input tensors and target tensors.\n",
    "    Define a network of layers (or model) that maps your inputs to your targets.\n",
    "    Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    "    Iterate on your training data by calling the fit() method of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Setting up a deep-learning workstation\n",
    "#### 3.3.1. Jupyter notebooks: the preferred way to run deep-learning experiments\n",
    "#### 3.3.2. Getting Keras running: two options\n",
    "#### 3.3.3. Running deep-learning jobs in the cloud: pros and cons\n",
    "#### 3.3.4. What is the best GPU for deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Classifying movie reviews: a binary classification example\n",
    "#### 3.4.1. The IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 49s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 12s 8us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()                                    \n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])            \n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2. Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))        \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.                          \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)                  \n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
