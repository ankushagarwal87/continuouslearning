{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. A first look at a neural network\n",
    "\n",
    "####  Loading the MNIST dataset in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 99s 9us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The network architecture\n",
    "    The core building block of neural networks is the layer, a data-processing module that you can think of as a filter for data. Some data goes in, and it comes out in a more useful form. Specifically, layers extract representations out of the data fed into them—hopefully, representations that are more meaningful for the problem at hand. Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation. A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters—the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The compilation step\n",
    "    To make the network ready for training, we need to pick three more things, as part of the compilation step\n",
    "##### A loss function\n",
    "    How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "##### An optimizer\n",
    "    The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "##### Metrics \n",
    "    To monitor during training and testing— Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.2559 - acc: 0.9253\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.1024 - acc: 0.9698\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0677 - acc: 0.9797\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0485 - acc: 0.9856\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0363 - acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3724570f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 79us/step\n",
      "test_acc: 0.9813\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data representations for neural networks\n",
    "\n",
    "#### 2.2.1. Scalars (0D tensors)\n",
    "#### 2.2.2. Vectors (1D tensors)\n",
    "#### 2.2.3. Matrices (2D tensors)\n",
    "#### 2.2.4. 3D tensors and higher-dimensional tensors\n",
    "#### 2.2.5. Key attributes\n",
    "    Number of axes (rank)\n",
    "    Shape\n",
    "    Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(60000, 784)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6. Manipulating tensors in Numpy\n",
    "#### 2.2.7. The notion of data batches\n",
    "#### 2.2.8. Real-world examples of data tensors\n",
    "    Vector data— 2D tensors of shape (samples, features)\n",
    "    Timeseries data or sequence data— 3D tensors of shape (samples, timesteps, features)\n",
    "    Images— 4D tensors of shape (samples, height, width, channels) or (samples, channels, height, width)\n",
    "    Video— 5D tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)\n",
    "    \n",
    "#### 2.2.9. Vector data\n",
    "#### 2.2.10. Timeseries data or sequence data\n",
    "#### 2.2.11. Image data\n",
    "#### 2.2.12. Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. The gears of neural networks: tensor operations\n",
    "#### 2.3.1. Element-wise operations\n",
    "#### 2.3.2. Broadcasting\n",
    "#### 2.3.3. Tensor dot\n",
    "#### 2.3.4. Tensor reshaping\n",
    "#### 2.3.5. Geometric interpretation of tensor operations\n",
    "#### 2.3.6. A geometric interpretation of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. The engine of neural networks: gradient-based optimization\n",
    "    \n",
    "    Draw a batch of training samples x and corresponding targets y.\n",
    "    Run the network on x (a step called the forward pass) to obtain predictions y_pred.\n",
    "    Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
    "    Update all weights of the network in a way that slightly reduces the loss on this batch.\n",
    "    \n",
    "#### 2.4.1. What’s a derivative?\n",
    "    Consider a continuous, smooth function f(x) = y, mapping a real number x to a new real number y. Because the function is continuous, a small change in x can only result in a small change in y—that’s the intuition behind continuity. Let’s say you increase x by a small factor epsilon_x: this results in a small epsilon_y change to y:\n",
    "    f(x + epsilon_x) = y + epsilon_y\n",
    "    \n",
    "    because the function is smooth (its curve doesn’t have any abrupt angles), when epsilon_x is small enough, around a certain point p, it’s possible to approximate f as a linear function of slope a, so that epsilon_y becomes a * epsilon_x:\n",
    "    f(x + epsilon_x) = y + a * epsilon_x\n",
    "\n",
    "    The slope a is called the derivative of f in p. If a is negative, it means a small change of x around p will result in a decrease of f(x) (as shown in figure 2.10); and if a is positive, a small change in x will result in an increase of f(x). Further, the absolute value of a (the magnitude of the derivative) tells you how quickly this increase or decrease will happen.\n",
    "    \n",
    "#### 2.4.2. Derivative of a tensor operation: the gradient\n",
    "\n",
    "    A gradient is the derivative of a tensor operation. It’s the generalization of the concept of derivatives to functions of multidimensional inputs: that is, to functions that take tensors as inputs.\n",
    "    \n",
    "    y_pred = dot(W, x)\n",
    "    loss_value = loss(y_pred, y)\n",
    "    loss_value = f(W)\n",
    "    \n",
    "    Let’s say the current value of W is W0. Then the derivative of f in the point W0 is a tensor gradient(f)(W0) with the same shape as W, where each coefficient gradient(f) (W0)[i, j] indicates the direction and magnitude of the change in loss_value you observe when modifying W0[i, j]. That tensor gradient(f)(W0) is the gradient of the function f(W) = loss_value in W0.\n",
    "\n",
    "    You saw earlier that the derivative of a function f(x) of a single coefficient can be interpreted as the slope of the curve of f. Likewise, gradient(f)(W0) can be interpreted as the tensor describing the curvature of f(W) around W0.\n",
    "\n",
    "    For this reason, in much the same way that, for a function f(x), you can reduce the value of f(x) by moving x a little in the opposite direction from the derivative, with a function f(W) of a tensor, you can reduce f(W) by moving W in the opposite direction from the gradient: for example, W1 = W0 - step * gradient(f)(W0) (where step is a small scaling factor). That means going against the curvature, which intuitively should put you lower on the curve. Note that the scaling factor step is needed because gradient(f)(W0) only approximates the curvature when you’re close to W0, so you don’t want to get too far from W0.\n",
    "    \n",
    "#### 2.4.3. Stochastic gradient descent\n",
    "\n",
    "    \n",
    "    Draw a batch of training samples x and corresponding targets y.\n",
    "    Run the network on x to obtain predictions y_pred.\n",
    "    Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
    "    Compute the gradient of the loss with regard to the network’s parameters (a backward pass).\n",
    "    Move the parameters a little in the opposite direction from the gradient—for example W = step * gradient—thus reducing the loss on the batch a bit.\n",
    "\n",
    "    The term stochastic refers to the fact that each batch of data is drawn at random (stochastic is a scientific synonym of random)\n",
    "    \n",
    "    Additionally, there exist multiple variants of SGD that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the current value of the gradients. There is, for instance, SGD with momentum, as well as Adagrad, RMSProp, and several others. Such variants are known as optimization methods or optimizers. In particular, the concept of momentum, which is used in many of these variants, deserves your attention. Momentum addresses two issues with SGD: convergence speed and local minima\n",
    "    \n",
    "    As you can see, around a certain parameter value, there is a local minimum: around that point, moving left would result in the loss increasing, but so would moving right. If the parameter under consideration were being optimized via SGD with a small learning rate, then the optimization process would get stuck at the local minimum instead of making its way to the global minimum.\n",
    "\n",
    "    You can avoid such issues by using momentum, which draws inspiration from physics. A useful mental image here is to think of the optimization process as a small ball rolling down the loss curve. If it has enough momentum, the ball won’t get stuck in a ravine and will end up at the global minimum. Momentum is implemented by moving the ball at each step based not only on the current slope value (current acceleration) but also on the current velocity (resulting from past acceleration). In practice, this means updating the parameter w based not only on the current gradient value but also on the previous parameter update, such as in this naive implementation:\n",
    "    \n",
    "#### 2.4.4. Chaining derivatives: the Backpropagation algorithm\n",
    "#### 2.5. Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
