{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Key Services\n",
    "> Introduction to AWS Additional Key Services\n",
    "\n",
    "- toc: true \n",
    "- comments: true\n",
    "- author: Ankush Agarwal\n",
    "- categories: [aws, Additional Key Services]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon CloudFront\n",
    "    A Content Delivery Network (CDN) is a globally distributed network of caching servers that speed up \n",
    "        the downloading of web pages and other content.\n",
    "    Amazon CloudFront is AWS CDN. It can be used to deliver your web content using Amazon’s global network \n",
    "        of edge locations\n",
    "        \n",
    "    Distributions To use Amazon CloudFront, you start by creating a distribution, which is identified by a \n",
    "        DNS domain name such as d111111abcdef8.cloudfront.net\n",
    "    Origins When you create a distribution, you must specify the DNS domain name of the origin—the Amazon \n",
    "        S3 bucket or HTTP server—from which you want Amazon CloudFront to get the definitive version of \n",
    "        your objects (web files). \n",
    "    Cache Control Once requested and served from an edge location, objects stay in the cache until they expire\n",
    "        or are evicted to make room for more frequently requested content\n",
    "    \n",
    "    Signed URLs Use URLs that are valid only between certain times and optionally from certain IP addresses.\n",
    "    Signed Cookies Require authentication via public and private key pairs.\n",
    "    Origin Access Identities (OAI) Restrict access to an Amazon S3 bucket only to a special Amazon CloudFront\n",
    "        user associated with your distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Storage Gateway\n",
    "    AWS Storage Gateway is a service connecting an on-premises software appliance with cloud-based storage \n",
    "        to provide seamless and secure integration between an organization’s on-premises IT environment and \n",
    "        AWS storage infrastructure.\n",
    "        \n",
    "    Gateway-Cached Volumes \n",
    "    Gateway-Cached volumes allow you to expand your local storage capacity into Amazon S3. \n",
    "    All data stored on a Gateway-Cached volume is moved to Amazon S3, while recently read data is retained in \n",
    "        local storage to provide low-latency access. \n",
    "    While each volume is limited to a maximum size of 32TB, a single gateway can support up to 32 volumes \n",
    "        for a maximum storage of 1 PB.\n",
    "    All Gateway-Cached volume data and snapshot data is transferred to Amazon S3 over encrypted Secure \n",
    "        Sockets Layer (SSL) connections. \n",
    "    It is encrypted at rest in Amazon S3 using Server-Side Encryption (SSE). \n",
    "    However, you cannot directly access this data with the Amazon S3 API or other tools such as the \n",
    "        Amazon S3 console; instead you must access it through the AWS Storage Gateway service.\n",
    "    \n",
    "    Gateway-Stored Volumes \n",
    "    Gateway-Stored volumes allow you to store your data on your on-premises storage and asynchronously back \n",
    "        up that data to Amazon S3. \n",
    "    This provides low-latency access to all data, while also providing off-site backups taking advantage of \n",
    "        the durability of Amazon S3. \n",
    "    The data is backed up in the form of Amazon Elastic Block Store (Amazon EBS) snapshots. \n",
    "    While each volume is limited to a maximum size of 16TB, a single gateway can support up to 32 volumes \n",
    "        for a maximum storage of 512TB.\n",
    "        \n",
    "    Gateway Virtual Tape Libraries (VTL) \n",
    "    Gateway-VTL offers a durable, cost-effective solution to archive your data on the AWS cloud. \n",
    "    The VTL interface lets you leverage your existing tape-based backup application infrastructure to store \n",
    "        data on virtual tape cartridges that you create on your Gateway-VTL.\n",
    "    A gateway can contain up to 1,500 tapes (1 PB) of total tape data. \n",
    "    Virtual tapes appear in your gateway’s VTL, a virtualized version of a physical tape library.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Directory Service\n",
    "    AWS Directory Service is a managed service offering that provides directories that contain information \n",
    "        about your organization, including users, groups, computers, and other resources.\n",
    "    \n",
    "    AWS Directory Service for Microsoft Active Directory(Enterprise Edition),also referred to as Microsoft AD\n",
    "    Simple AD\n",
    "    AD Connector\n",
    "        AD Connector is a proxy service for connecting your on-premises Microsoft Active Directory to the \n",
    "            AWS cloud without requiring complex directory synchronization or the cost and complexity of \n",
    "            hosting a federation infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Key Management Service (KMS) and AWS CloudHSM    \n",
    "    AWS KMS: A service enabling you to generate, store, enable/disable, and delete symmetric keys\n",
    "    AWS CloudHSM: A service providing you with secure cryptographic key storage by making Hardware \n",
    "        Security Modules (HSMs) available on the AWS cloud\n",
    "        \n",
    "    Customer Managed Keys \n",
    "    AWS KMS uses a type of key called a Customer Master Key (CMK) to encrypt and decrypt data.\n",
    "    CMKs are the fundamental resources that AWS KMS manages. \n",
    "    They can be used inside of AWS KMS to encrypt or decrypt up to 4 KB of data directly. \n",
    "    They can also be used to encrypt generated data keys that are then used to encrypt or decrypt larger \n",
    "        amounts of data outside of the service.\n",
    "    \n",
    "    Data Keys \n",
    "    You use data keys to encrypt large data objects within your own application outside AWS KMS.\n",
    "    When you call GenerateDataKey, AWS KMS returns a plaintext version of the key and ciphertext that \n",
    "        contains the key encrypted under the specified CMK. \n",
    "    AWS KMS tracks which CMK was used to encrypt the data key.\n",
    "    You use the plaintext data key in your application to encrypt data, and you typically store the \n",
    "        encrypted key alongside your encrypted data.\n",
    "    To decrypt data in your application, pass the encrypted data key to the Decrypt function. \n",
    "    AWS KMS uses the associated CMK to decrypt and retrieve your plaintext data key. \n",
    "    Use the plaintext key to decrypt your data, and then remove the key from memory.\n",
    "    \n",
    "    AWS CloudHSM \n",
    "    AWS CloudHSM helps you meet corporate, contractual, and regulatory compliance requirements for data \n",
    "        security by using dedicated HSM appliances within the AWS cloud. \n",
    "    An HSM is a hardware appliance that provides secure key storage and cryptographic operations within a \n",
    "        tamper-resistant hardware module. \n",
    "    HSMs are designed to securely store cryptographic key material and use the key material without \n",
    "        exposing it outside the cryptographic boundary of the appliance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS CloudTrail\n",
    "    AWS CloudTrail provides visibility into user activity by recording API calls made on your account. \n",
    "    AWS CloudTrail records important information about each API call, including the name of the API, \n",
    "        the identity of the caller, the time of the API call, the request parameters, and the response \n",
    "        elements returned by the AWS service\n",
    "        \n",
    "    A Trail That Applies to All Regions \n",
    "        When you create a trail that applies to all AWS regions, AWS CloudTrail creates the same trail in each \n",
    "        region, records the log files in each region, and delivers the log files to the single Amazon S3 \n",
    "        bucket (and optionally to the Amazon CloudWatch Logs log group) that you specify. \n",
    "        This is the default option when you create a trail using the AWS CloudTrail console.\n",
    "        \n",
    "    A Trail That Applies to One Region \n",
    "        You specify a bucket that receives events only from that region. \n",
    "        The bucket can be in any region that you specify. \n",
    "        If you create additional individual trails that apply to specific regions, you can have those \n",
    "            trails deliver event logs to a single Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Kinesis\n",
    "    Amazon Kinesis is a platform for handling massive streaming data on AWS, offering powerful services \n",
    "        to make it easy to load and analyze streaming data and also providing the ability for you to build \n",
    "        custom streaming data applications for specialized needs.\n",
    "        \n",
    "    Amazon Kinesis Firehose:A service enabling you to load massive volumes of streaming data into AWS\n",
    "    Amazon Kinesis Streams:A service enabling you to build custom applications for more complex analysis \n",
    "        of streaming data in real time\n",
    "    Amazon Kinesis Analytics:A service enabling you to easily analyze streaming data real time with standard SQL\n",
    "    \n",
    "    Amazon Kinesis Firehose \n",
    "        Amazon Kinesis Firehose receives stream data and stores it in Amazon S3, Amazon Redshift, or Amazon\n",
    "        Elasticsearch. You do not need to write any code; just create a delivery stream and configure the\n",
    "        destination for your data. Clients write data to the stream using an AWS API call and the data is\n",
    "        automatically sent to the proper destination.\n",
    "        \n",
    "    Amazon Kinesis Streams \n",
    "        Amazon Kinesis Streams enable you to collect and process large streams of data records in real time.\n",
    "        Using AWS SDKs, you can create an Amazon Kinesis Streams application that processes the data as it\n",
    "        moves through the stream. Because response time for data intake and processing is in near real time,\n",
    "        the processing is typically lightweight. Amazon Kinesis Streams can scale to support nearly limitless \n",
    "        data streams by distributing incoming data across a number of shards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Elastic MapReduce (Amazon EMR)\n",
    "    Amazon Elastic MapReduce (Amazon EMR) provides you with a fully managed, on-demand Hadoop framework. \n",
    "    Amazon EMR reduces the complexity and up-front costs of setting up Hadoop and, combined with the scale of \n",
    "    AWS, gives you the ability to spin up large Hadoop clusters instantly and start processing within minutes.\n",
    "    \n",
    "    Hadoop Distributed File System (HDFS) \n",
    "    HDFS is the standard file system that comes with Hadoop. \n",
    "    All data is replicated across multiple instances to ensure durability. Amazon EMR can use Amazon EC2 \n",
    "    instance storage or Amazon EBS for HDFS. When a cluster is shut down, instance storage is lost and the \n",
    "    data does not persist. HDFS can also make use of Amazon EBS storage, trading in the cost effectiveness \n",
    "    of instance storage for the ability to shut down a cluster without losing data.\n",
    "\n",
    "    EMR File System (EMRFS) \n",
    "    EMRFS is an implementation of HDFS that allows clusters to store data on Amazon S3.\n",
    "    EMRFS allows you to get the durability and low cost of Amazon S3 while preserving your data even if the \n",
    "    cluster is shut down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Data Pipeline\n",
    "    AWS Data Pipeline is a web service that helps you reliably process and move data between different AWS \n",
    "    compute and storage services, and also on-premises data sources, at specified intervals. \n",
    "    With AWS Data Pipeline, you can regularly access your data where it’s stored, transform and process it \n",
    "    at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon Relational \n",
    "    Database Service (Amazon RDS), Amazon DynamoDB, and Amazon EMR.\n",
    "    \n",
    "![](my_icons/Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Import/Export\n",
    "    AWS Snowball \n",
    "    AWS Snowball uses Amazon-provided shippable storage appliances shipped through UPS. \n",
    "    Each AWS Snowball is protected by AWS KMS and made physically rugged to secure and protect your data \n",
    "    while the device is in transit. \n",
    "    At the time of this writing, AWS Snowballs come in two sizes: 50TB and 80TB, and the availability of \n",
    "    each varies by region.\n",
    "    You can import and export data between your on-premises data storage locations and Amazon S3.\n",
    "    \n",
    "    AWS Import/Export Disk \n",
    "    AWS Import/Export Disk supports transfers data directly onto and off of storage devices you own using \n",
    "    the Amazon high-speed internal network.\n",
    "    You can import your data into Amazon Glacier and Amazon EBS, in addition to Amazon S3.\n",
    "    You can export data from Amazon S3.\n",
    "    Encryption is optional and not enforced.\n",
    "    Unlike AWS Snowball, AWS Import/Export Disk has an upper limit of 16TB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevOps\n",
    "    AWS OpsWorks is a configuration management service that helps you configure and operate applications \n",
    "    using Chef.    \n",
    "    You can define an application’s architecture and the specification of each component, including \n",
    "    package installation, software configuration, and resources such as storage.\n",
    "![](my_icons/Ops.png)    \n",
    "    \n",
    "    The stack is the core AWS OpsWorks component. \n",
    "    It is basically a container for AWS resources—Amazon EC2 instances, Amazon RDS database instances, \n",
    "    and so on—that have a common purpose and make sense to be logically managed together.\n",
    "    You define the elements of a stack by adding one or more layers. \n",
    "    A layer represents a set of resources that serve a particular purpose, such as load balancing, \n",
    "    web applications, or hosting a database server.\n",
    "    One of the key AWS OpsWorks features is a set of lifecycle events that automatically run a specified \n",
    "    set of recipes at the appropriate time on each instance.\n",
    "    Finally, AWS OpsWorks sends all of your resource metrics to Amazon CloudWatch, making it easy to view\n",
    "    graphs and set alarms to help you troubleshoot and take automated action based on the state of your resources\n",
    "    Use Cases   \n",
    "        Host Multi-Tier Web Applications \n",
    "        Support Continuous Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS CloudFormation\n",
    "    AWS CloudFormation is a service that helps you model and set up your AWS resources so that you can spend\n",
    "    less time managing those resources and more time focusing on your applications that run in AWS.\n",
    "    You create AWS CloudFormation templates to define your AWS resources and their properties. \n",
    "    A template is a text file whose format complies with the JSON standard. \n",
    "    AWS CloudFormation uses these templates as blueprints for building your AWS resources.\n",
    "\n",
    "![](my_icons/CF.png) \n",
    "\n",
    "    Use Case\n",
    "        Quickly Launch New Test Environments\n",
    "        Reliably Replicate Configuration Between Environments\n",
    "        Launch Applications in New AWS Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Elastic Beanstalk\n",
    "    AWS Elastic Beanstalk is the fastest and simplest way to get an application up and running on AWS. \n",
    "    Developers can simply upload their application code, and the service automatically handles all of the \n",
    "    details, such as resource provisioning, load balancing, Auto Scaling, and monitoring.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Trusted Advisor\n",
    "    AWS Trusted Advisor draws upon best practices learned from the aggregated operational history of serving \n",
    "    over a million AWS customers\n",
    "    AWS Trusted Advisor provides best practices in four categories: cost optimization, security, \n",
    "    fault tolerance, and performance improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Config\n",
    "    AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration \n",
    "    history, and configuration change notifications to enable security and governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
