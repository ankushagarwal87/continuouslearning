<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ankushagarwal87.github.io/continuouslearning/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ankushagarwal87.github.io/continuouslearning/" rel="alternate" type="text/html" /><updated>2020-08-15T13:53:01-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/feed.xml</id><title type="html">continuouslearning</title><subtitle>An easy to use blogging platform with support for Jupyter Notebooks.</subtitle><entry><title type="html">AWS VPC - NAT vs EndPoint</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/2020/08/15/NAT-Gateway-vs-VPC-Gateway-End-Point.html" rel="alternate" type="text/html" title="AWS VPC - NAT vs EndPoint" /><published>2020-08-15T00:00:00-05:00</published><updated>2020-08-15T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/2020/08/15/NAT-Gateway-vs-VPC-Gateway-End-Point</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/2020/08/15/NAT-Gateway-vs-VPC-Gateway-End-Point.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-15-NAT Gateway vs VPC Gateway End Point.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Comparison&quot;&gt;Comparison&lt;a class=&quot;anchor-link&quot; href=&quot;#Comparison&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;The following table shows the options you have if you decide to stay in private subnets.
                        Gateway VPC Endpoint    Interface VPC Endpoint  NAT Gateway
Supported AWS services  S3, DynamoDB    some                    all
Price per hour1         free            $0.01                   $0.045
Price per GB1           free            $0.01                   $0.045

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, using Gateway VPC Endpoints is cheaper than using Interface VPC Endpoint which is cheaper than using NAT Gateways&lt;/p&gt;
&lt;p&gt;Nat Gateway Usage for 15 GB monthly usage for 1 NAT Gateway&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;730 hours in a month x 0.045 USD = 32.85 USD (Gateway usage hourly cost)
15 GB per month x 0.045 USD = 0.68 USD (NAT Gateway data processing cost)
32.85 USD + 0.68 USD = 33.53 USD (NAT Gateway processing and month hours)
1 NAT Gateways x 33.53 USD = 33.53 USD (Total NAT Gateway usage and data processing cost)

Total NAT Gateway usage and data processing cost (monthly): 33.53 USD


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;InterFace EndPoint Usage for 15 GB Monthly Usage for 1 VPC EndPoint&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;730 hours in a month x 0.01 USD = 7.30 USD (Hourly cost for endpoint ENI)
15 GB per month x 0.01 USD = 0.15 USD (PrivateLink data processing cost)
7.30 USD + 0.15 USD = 7.45 USD (Hourly cost and data processing per endpoint ENI)
1 VPC endpoints x 1 ENIs per VPC endpoint x 7.45 USD = 7.45 USD (Total PrivateLink endpoints and data processing cost)

Total PrivateLink endpoints and data processing cost (monthly): 7.45 USD


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gateway EndPoint Usage for 15 GB Monthly Usage&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Intra region:
(15 GB x 0.01 USD per GB outbound) + (15 GB x 0.01 USD per GB inbound) = 0.30 USD 

Data Transfer cost (monthly): 0.30 USD&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Question&quot;&gt;Question&lt;a class=&quot;anchor-link&quot; href=&quot;#Question&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;We don't need NAT Gateway in Prod to run 24*7 for accessing EC2 instance or we can run it only when needed
If its free atleast Data transfer charges will not apply &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html
https://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">Architecture Best Practices</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/architecture%20best%20practices/2020/08/11/Architecture-Best-Practices.html" rel="alternate" type="text/html" title="Architecture Best Practices" /><published>2020-08-11T00:00:00-05:00</published><updated>2020-08-11T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/architecture%20best%20practices/2020/08/11/Architecture-Best-Practices</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/architecture%20best%20practices/2020/08/11/Architecture-Best-Practices.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-11-Architecture Best Practices.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Overview&quot;&gt;Overview&lt;a class=&quot;anchor-link&quot; href=&quot;#Overview&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Design for failure and nothing will fail.
    Standby redundancy is often used for stateful components such as relational databases.
    Amazon Simple Storage Service (Amazon S3) and Amazon DynamoDB ensure that data is redundantly 
    stored across multiple facilities.

Implement elasticity.
    vertically and horizontally.
    Consider only storing a unique session identifier in a HTTP cookie and storing more detailed user 
    session information server-side. Most programming platforms provide a native session management 
    mechanism that works this way; however, these management mechanisms often store the session 
    information locally by default. This would result in a stateful architecture. 
    A common solution to this problem is to store user session information in a database. 
    Amazon DynamoDB is a great choice due to its scalability, high availability, and durability
    characteristics. For many platforms, there are open source, drop-in replacement libraries that 
    allow you to store native sessions in Amazon DynamoDB.

Leverage different storage options.        

Build security in every layer.
    Services like AWS Web Application Firewall (AWS WAF) can help protect your web applications 
    from SQL injection and other vulnerabilities in your application code
    With AWS Config Rules, you will also know if some component was out of compliance even for a brief 
    period of time, making both point-in-time and period-in-time audits very effective. 
    You can implement extensive logging for your applications using Amazon CloudWatch Logs and for the 
    actual AWS API calls by enabling AWS CloudTrail

Think parallel.
Loose coupling sets you free.
Don’t fear constraints.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">Security on AWS</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/security/2020/08/09/Security-on-AWS.html" rel="alternate" type="text/html" title="Security on AWS" /><published>2020-08-09T00:00:00-05:00</published><updated>2020-08-09T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/security/2020/08/09/Security-on-AWS</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/security/2020/08/09/Security-on-AWS.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-09-Security on AWS.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Network-Monitoring-and-Protection&quot;&gt;Network Monitoring and Protection&lt;a class=&quot;anchor-link&quot; href=&quot;#Network-Monitoring-and-Protection&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Distributed Denial of Service (DDoS) Attacks 
Man in the Middle (MITM) Attacks
IP Spoofing 
Port Scanning
Packet Sniffing by Other Tenants&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Account-Security-Features&quot;&gt;AWS Account Security Features&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Account-Security-Features&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Credentials
    Passwords
    Access Keys
    Key Pairs
    X.509 Certificates
AWS CloudTrail&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Service-Specific-Security&quot;&gt;Service-Specific Security&lt;a class=&quot;anchor-link&quot; href=&quot;#Service-Specific-Security&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Compute
    Amazon Elastic Compute Cloud
        Amazon EC2 supports RSA 2048 SSH-2 Key pairs
    Amazon Elastic Block Store (Amazon EBS) 
        Encrypt Amazon EBS volumes and their snapshots with AES-256

Networking
    Elastic Load Balancing
        configures your load balancer with a pre-defined cipher set that is used for TLS negotiation
    Amazon Virtual Private Cloud
        Security features within Amazon VPC include security groups, network ACLs, routing tables, 
        and external gateway
    Amazon CloudFront
        To control access to the original copies of your objects in Amazon S3, Amazon CloudFront allows 
        you to create one or more Origin Access Identities and associate these with your distributions.
        To control who can download objects from Amazon CloudFront edge locations, the service uses 
        a signed-URL verification system.

Storage
    Amazon Simple Storage Service
    Amazon Glacier
        encrypts the data using AES-256
    AWS Storage Gateway
        Transfer to AWS over SSL and stored encrypted in Amazon S3 using AES-256

Database
    Amazon DynamoDB
        You can control access at the database level 
    Amazon Relational Database Service
        You can control Amazon RDS DB Instance access via DB security groups
    Amazon Redshift
         AES-256 block encryption
    Amazon ElastiCache
        Cache Security Group

Application Services
    Amazon Simple Queue Service
        AWS account or a user created with AWS IAM
    Amazon Simple Notification Service
        Amazon SNS allows topic owners to set policies for a topic that restrict who can publish or 
        subscribe to a topic

Analytics
    Amazon Elastic MapReduce
    Amazon Kinesis
        users under your AWS account using AWS IAM

Deployment and Management
    AWS Identity and Access Management

Mobile Services
    Amazon Cognito
        Your application authenticates with one of the well-known identity providers such as Google, 
        Facebook, and Amazon using the provider’s SDK
        After the end user is authenticated with the provider, an OAuth or OpenID Connect token returned 
        from the provider is passed by your application to Amazon Cognito, which returns a new Amazon 
        Cognito ID for the user and a set of temporary, limited-privilege AWS credentials.

Applications
    Amazon Workspaces &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">Additional Key Services</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/additional%20key%20services/2020/07/26/Additional-Key-Services.html" rel="alternate" type="text/html" title="Additional Key Services" /><published>2020-07-26T00:00:00-05:00</published><updated>2020-07-26T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/additional%20key%20services/2020/07/26/Additional-Key-Services</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/additional%20key%20services/2020/07/26/Additional-Key-Services.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-26-Additional Key Services.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-CloudFront&quot;&gt;Amazon CloudFront&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-CloudFront&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;A Content Delivery Network (CDN) is a globally distributed network of caching servers that speed up 
    the downloading of web pages and other content.
Amazon CloudFront is AWS CDN. It can be used to deliver your web content using Amazon’s global network 
    of edge locations

Distributions To use Amazon CloudFront, you start by creating a distribution, which is identified by a 
    DNS domain name such as d111111abcdef8.cloudfront.net
Origins When you create a distribution, you must specify the DNS domain name of the origin—the Amazon 
    S3 bucket or HTTP server—from which you want Amazon CloudFront to get the definitive version of 
    your objects (web files). 
Cache Control Once requested and served from an edge location, objects stay in the cache until they expire
    or are evicted to make room for more frequently requested content

Signed URLs Use URLs that are valid only between certain times and optionally from certain IP addresses.
Signed Cookies Require authentication via public and private key pairs.
Origin Access Identities (OAI) Restrict access to an Amazon S3 bucket only to a special Amazon CloudFront
    user associated with your distribution.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Storage-Gateway&quot;&gt;AWS Storage Gateway&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Storage-Gateway&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Storage Gateway is a service connecting an on-premises software appliance with cloud-based storage 
    to provide seamless and secure integration between an organization’s on-premises IT environment and 
    AWS storage infrastructure.

Gateway-Cached Volumes 
Gateway-Cached volumes allow you to expand your local storage capacity into Amazon S3. 
All data stored on a Gateway-Cached volume is moved to Amazon S3, while recently read data is retained in 
    local storage to provide low-latency access. 
While each volume is limited to a maximum size of 32TB, a single gateway can support up to 32 volumes 
    for a maximum storage of 1 PB.
All Gateway-Cached volume data and snapshot data is transferred to Amazon S3 over encrypted Secure 
    Sockets Layer (SSL) connections. 
It is encrypted at rest in Amazon S3 using Server-Side Encryption (SSE). 
However, you cannot directly access this data with the Amazon S3 API or other tools such as the 
    Amazon S3 console; instead you must access it through the AWS Storage Gateway service.

Gateway-Stored Volumes 
Gateway-Stored volumes allow you to store your data on your on-premises storage and asynchronously back 
    up that data to Amazon S3. 
This provides low-latency access to all data, while also providing off-site backups taking advantage of 
    the durability of Amazon S3. 
The data is backed up in the form of Amazon Elastic Block Store (Amazon EBS) snapshots. 
While each volume is limited to a maximum size of 16TB, a single gateway can support up to 32 volumes 
    for a maximum storage of 512TB.

Gateway Virtual Tape Libraries (VTL) 
Gateway-VTL offers a durable, cost-effective solution to archive your data on the AWS cloud. 
The VTL interface lets you leverage your existing tape-based backup application infrastructure to store 
    data on virtual tape cartridges that you create on your Gateway-VTL.
A gateway can contain up to 1,500 tapes (1 PB) of total tape data. 
Virtual tapes appear in your gateway’s VTL, a virtualized version of a physical tape library.    &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Directory-Service&quot;&gt;AWS Directory Service&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Directory-Service&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Directory Service is a managed service offering that provides directories that contain information 
    about your organization, including users, groups, computers, and other resources.

AWS Directory Service for Microsoft Active Directory(Enterprise Edition),also referred to as Microsoft AD
Simple AD
AD Connector
    AD Connector is a proxy service for connecting your on-premises Microsoft Active Directory to the 
        AWS cloud without requiring complex directory synchronization or the cost and complexity of 
        hosting a federation infrastructure.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Key-Management-Service-(KMS)-and-AWS-CloudHSM&quot;&gt;AWS Key Management Service (KMS) and AWS CloudHSM&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Key-Management-Service-(KMS)-and-AWS-CloudHSM&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS KMS: A service enabling you to generate, store, enable/disable, and delete symmetric keys
AWS CloudHSM: A service providing you with secure cryptographic key storage by making Hardware 
    Security Modules (HSMs) available on the AWS cloud

Customer Managed Keys 
AWS KMS uses a type of key called a Customer Master Key (CMK) to encrypt and decrypt data.
CMKs are the fundamental resources that AWS KMS manages. 
They can be used inside of AWS KMS to encrypt or decrypt up to 4 KB of data directly. 
They can also be used to encrypt generated data keys that are then used to encrypt or decrypt larger 
    amounts of data outside of the service.

Data Keys 
You use data keys to encrypt large data objects within your own application outside AWS KMS.
When you call GenerateDataKey, AWS KMS returns a plaintext version of the key and ciphertext that 
    contains the key encrypted under the specified CMK. 
AWS KMS tracks which CMK was used to encrypt the data key.
You use the plaintext data key in your application to encrypt data, and you typically store the 
    encrypted key alongside your encrypted data.
To decrypt data in your application, pass the encrypted data key to the Decrypt function. 
AWS KMS uses the associated CMK to decrypt and retrieve your plaintext data key. 
Use the plaintext key to decrypt your data, and then remove the key from memory.

AWS CloudHSM 
AWS CloudHSM helps you meet corporate, contractual, and regulatory compliance requirements for data 
    security by using dedicated HSM appliances within the AWS cloud. 
An HSM is a hardware appliance that provides secure key storage and cryptographic operations within a 
    tamper-resistant hardware module. 
HSMs are designed to securely store cryptographic key material and use the key material without 
    exposing it outside the cryptographic boundary of the appliance.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-CloudTrail&quot;&gt;AWS CloudTrail&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-CloudTrail&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS CloudTrail provides visibility into user activity by recording API calls made on your account. 
AWS CloudTrail records important information about each API call, including the name of the API, 
    the identity of the caller, the time of the API call, the request parameters, and the response 
    elements returned by the AWS service

A Trail That Applies to All Regions 
    When you create a trail that applies to all AWS regions, AWS CloudTrail creates the same trail in each 
    region, records the log files in each region, and delivers the log files to the single Amazon S3 
    bucket (and optionally to the Amazon CloudWatch Logs log group) that you specify. 
    This is the default option when you create a trail using the AWS CloudTrail console.

A Trail That Applies to One Region 
    You specify a bucket that receives events only from that region. 
    The bucket can be in any region that you specify. 
    If you create additional individual trails that apply to specific regions, you can have those 
        trails deliver event logs to a single Amazon S3 bucket.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Kinesis&quot;&gt;Amazon Kinesis&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Kinesis&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon Kinesis is a platform for handling massive streaming data on AWS, offering powerful services 
    to make it easy to load and analyze streaming data and also providing the ability for you to build 
    custom streaming data applications for specialized needs.

Amazon Kinesis Firehose:A service enabling you to load massive volumes of streaming data into AWS
Amazon Kinesis Streams:A service enabling you to build custom applications for more complex analysis 
    of streaming data in real time
Amazon Kinesis Analytics:A service enabling you to easily analyze streaming data real time with standard SQL

Amazon Kinesis Firehose 
    Amazon Kinesis Firehose receives stream data and stores it in Amazon S3, Amazon Redshift, or Amazon
    Elasticsearch. You do not need to write any code; just create a delivery stream and configure the
    destination for your data. Clients write data to the stream using an AWS API call and the data is
    automatically sent to the proper destination.

Amazon Kinesis Streams 
    Amazon Kinesis Streams enable you to collect and process large streams of data records in real time.
    Using AWS SDKs, you can create an Amazon Kinesis Streams application that processes the data as it
    moves through the stream. Because response time for data intake and processing is in near real time,
    the processing is typically lightweight. Amazon Kinesis Streams can scale to support nearly limitless 
    data streams by distributing incoming data across a number of shards&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Elastic-MapReduce-(Amazon-EMR)&quot;&gt;Amazon Elastic MapReduce (Amazon EMR)&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Elastic-MapReduce-(Amazon-EMR)&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon Elastic MapReduce (Amazon EMR) provides you with a fully managed, on-demand Hadoop framework. 
Amazon EMR reduces the complexity and up-front costs of setting up Hadoop and, combined with the scale of 
AWS, gives you the ability to spin up large Hadoop clusters instantly and start processing within minutes.

Hadoop Distributed File System (HDFS) 
HDFS is the standard file system that comes with Hadoop. 
All data is replicated across multiple instances to ensure durability. Amazon EMR can use Amazon EC2 
instance storage or Amazon EBS for HDFS. When a cluster is shut down, instance storage is lost and the 
data does not persist. HDFS can also make use of Amazon EBS storage, trading in the cost effectiveness 
of instance storage for the ability to shut down a cluster without losing data.

EMR File System (EMRFS) 
EMRFS is an implementation of HDFS that allows clusters to store data on Amazon S3.
EMRFS allows you to get the durability and low cost of Amazon S3 while preserving your data even if the 
cluster is shut down.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Data-Pipeline&quot;&gt;AWS Data Pipeline&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Data-Pipeline&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Data Pipeline is a web service that helps you reliably process and move data between different AWS 
compute and storage services, and also on-premises data sources, at specified intervals. 
With AWS Data Pipeline, you can regularly access your data where it’s stored, transform and process it 
at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon Relational 
Database Service (Amazon RDS), Amazon DynamoDB, and Amazon EMR.

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/Pipeline.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Import/Export&quot;&gt;AWS Import/Export&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Import/Export&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Snowball 
AWS Snowball uses Amazon-provided shippable storage appliances shipped through UPS. 
Each AWS Snowball is protected by AWS KMS and made physically rugged to secure and protect your data 
while the device is in transit. 
At the time of this writing, AWS Snowballs come in two sizes: 50TB and 80TB, and the availability of 
each varies by region.
You can import and export data between your on-premises data storage locations and Amazon S3.

AWS Import/Export Disk 
AWS Import/Export Disk supports transfers data directly onto and off of storage devices you own using 
the Amazon high-speed internal network.
You can import your data into Amazon Glacier and Amazon EBS, in addition to Amazon S3.
You can export data from Amazon S3.
Encryption is optional and not enforced.
Unlike AWS Snowball, AWS Import/Export Disk has an upper limit of 16TB.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;DevOps&quot;&gt;DevOps&lt;a class=&quot;anchor-link&quot; href=&quot;#DevOps&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS OpsWorks is a configuration management service that helps you configure and operate applications 
using Chef.    
You can define an application’s architecture and the specification of each component, including 
package installation, software configuration, and resources such as storage.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/Ops.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The stack is the core AWS OpsWorks component. 
It is basically a container for AWS resources—Amazon EC2 instances, Amazon RDS database instances, 
and so on—that have a common purpose and make sense to be logically managed together.
You define the elements of a stack by adding one or more layers. 
A layer represents a set of resources that serve a particular purpose, such as load balancing, 
web applications, or hosting a database server.
One of the key AWS OpsWorks features is a set of lifecycle events that automatically run a specified 
set of recipes at the appropriate time on each instance.
Finally, AWS OpsWorks sends all of your resource metrics to Amazon CloudWatch, making it easy to view
graphs and set alarms to help you troubleshoot and take automated action based on the state of your resources
Use Cases   
    Host Multi-Tier Web Applications 
    Support Continuous Integration&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-CloudFormation&quot;&gt;AWS CloudFormation&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-CloudFormation&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS CloudFormation is a service that helps you model and set up your AWS resources so that you can spend
less time managing those resources and more time focusing on your applications that run in AWS.
You create AWS CloudFormation templates to define your AWS resources and their properties. 
A template is a text file whose format complies with the JSON standard. 
AWS CloudFormation uses these templates as blueprints for building your AWS resources.

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/CF.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Use Case
    Quickly Launch New Test Environments
    Reliably Replicate Configuration Between Environments
    Launch Applications in New AWS Regions&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Elastic-Beanstalk&quot;&gt;AWS Elastic Beanstalk&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Elastic-Beanstalk&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Elastic Beanstalk is the fastest and simplest way to get an application up and running on AWS. 
Developers can simply upload their application code, and the service automatically handles all of the 
details, such as resource provisioning, load balancing, Auto Scaling, and monitoring.   &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Trusted-Advisor&quot;&gt;AWS Trusted Advisor&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Trusted-Advisor&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Trusted Advisor draws upon best practices learned from the aggregated operational history of serving 
over a million AWS customers
AWS Trusted Advisor provides best practices in four categories: cost optimization, security, 
fault tolerance, and performance improvement&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;AWS-Config&quot;&gt;AWS Config&lt;a class=&quot;anchor-link&quot; href=&quot;#AWS-Config&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration 
history, and configuration change notifications to enable security and governance&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">Amazon ElastiCache</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/elasticache/2020/07/24/Amazon-ElastiCache.html" rel="alternate" type="text/html" title="Amazon ElastiCache" /><published>2020-07-24T00:00:00-05:00</published><updated>2020-07-24T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/elasticache/2020/07/24/Amazon-ElastiCache</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/elasticache/2020/07/24/Amazon-ElastiCache.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-24-Amazon ElastiCache.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-ElastiCache&quot;&gt;Amazon ElastiCache&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-ElastiCache&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;With Amazon ElastiCache, you can choose from a Memcached or Redis protocol-compliant cache engine and 
    quickly launch a cluster within minutes.
Memcached provides a very simple interface that allows you to write and read objects into 
    in-memory key/value data stores.
With Amazon ElastiCache, you can elastically grow and shrink a cluster of Memcached nodes to meet your 
    demands. 
You can partition your cluster into shards and support parallelized operations for very high 
    performance throughput. 

Memcached deals with objects as blobs that can be retrieved using a unique key.
Unlike Memcached, Redis supports the ability to persist the in-memory data onto disk. 
This allows you to create snapshots that back up your data and then recover or replicate from the backups.
Redis clusters also can support up to five read replicas to offload read requests. 
In the event of failure of the primary node, a read replica can be promoted and become the new master 
    using Multi-AZ replication groups.
Redis also has advanced features that make it easy to sort and rank data.
A single Memcached cluster can contain up to 20 nodes. 
Redis clusters are always made up of a single node; however, multiple clusters can be grouped into a 
    Redis replication group.

Horizontal Scaling 
Amazon ElastiCache also adds additional functionality that allows you to scale horizontally the size of 
    your cache environment. 
This functionality differs depending on the cache engine you have selected. 
With Memcached, you can partition your data and scale horizontally to 20 nodes or more. 
With Auto Discovery, your application can discover Memcached nodes that are added or removed from a cluster
While you can only have one node handling write commands, you can have up to five read replicas 
    handling read-only requests.

Vertical Scaling
You can, however, quickly spin up a new cluster with the desired cache node types and start redirecting 
    traffic to the new cluster. 
It’s important to understand that a new Memcached cluster always starts empty, while a Redis cluster 
    can be initialized from a backup.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">DNS &amp;amp; Route 53</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/dns/route%2053/2020/07/24/Domain-Name-System-(DNS)-and-Amazon-Route-53.html" rel="alternate" type="text/html" title="DNS &amp; Route 53" /><published>2020-07-24T00:00:00-05:00</published><updated>2020-07-24T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/dns/route%2053/2020/07/24/Domain-Name-System-(DNS)-and-Amazon-Route-53</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/dns/route%2053/2020/07/24/Domain-Name-System-(DNS)-and-Amazon-Route-53.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-24-Domain Name System (DNS) and Amazon Route 53.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Domain-Name-System-(DNS)-Concepts&quot;&gt;Domain Name System (DNS) Concepts&lt;a class=&quot;anchor-link&quot; href=&quot;#Domain-Name-System-(DNS)-Concepts&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Top-Level Domains (TLDs)
    A Top-Level Domain (TLD) is the most general part of the domain. 
    The TLD is the farthest portion to the right (as separated by a dot). 
    Common TLDs are .com, .net, .org, .gov, .edu, and .io.

 Domain Names
     Each domain name becomes registered in a central database, known as the WhoIS database.

 IP Addresses
 Hosts
 Subdomains
 Fully Qualified Domain Name (FQDN)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/DNS.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Name Servers
    A name server is a computer designated to translate domain names into IP addresses.
Zone Files
    A zone file is a simple text file that contains the mappings between domain names and IP addresses.
Top-Level Domain (TLD) Name Registrars&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Route-53-Overview&quot;&gt;Amazon Route 53 Overview&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Route-53-Overview&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon Route 53 is a highly available and scalable cloud DNS web service
Amazon Route 53 performs three main functions:
    Domain registration
    DNS service
    Health checking
When you create a resource record set, you choose a routing policy, which determines how Amazon Route 53
    responds to queries. 
Routing policy options are simple, weighted, latency-based, failover, and geolocation.
Routing policies can be associated with health checks, so resource health status is considered before it 
    even becomes a candidate in a conditional decision tree.

Simple
This is the default routing policy when you create a new resource. 
Use a simple routing policy when you have a single resource that performs a given function for your domain

Weighted
With weighted DNS, you can associate multiple resources (such as Amazon Elastic Compute Cloud [Amazon EC2]
    instances or Elastic Load Balancing load balancers) with a single DNS name.

Latency-Based
Latency-based routing allows you to route your traffic based on the lowest network latency for your end 
    user (for example, using the AWS region that will give them the fastest response time).

Failover
Use a failover routing policy to configure active-passive failover, in which one resource takes all the 
    traffic when it’s available and the other resource takes all the traffic when the first resource 
    isn’t available.

Geolocation
Geolocation routing lets you choose where Amazon Route 53 will send your traffic based on the 
    geographic location of your users (the location from which DNS queries originate). &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">SQS, SWF, and SNS</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/sqs/swf/sns/2020/07/18/SQS,-SWF,-and-SNS.html" rel="alternate" type="text/html" title="SQS, SWF, and SNS" /><published>2020-07-18T00:00:00-05:00</published><updated>2020-07-18T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/sqs/swf/sns/2020/07/18/SQS,-SWF,-and-SNS</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/sqs/swf/sns/2020/07/18/SQS,-SWF,-and-SNS.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-18-SQS, SWF, and SNS.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Simple-Queue-Service-(Amazon-SQS)&quot;&gt;Amazon Simple Queue Service (Amazon SQS)&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Simple-Queue-Service-(Amazon-SQS)&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon SQS is a fast, reliable, scalable, and fully managed message queuing service.
Amazon SQS makes it simple and cost effective to decouple the components of a cloud application.
You can use Amazon SQS to transmit any volume of data, at any level of throughput

With Amazon SQS, you can offload the administrative burden of operating and scaling a highly 
    available messaging cluster while paying a low price for only what you use.
Amazon SQS ensures delivery of each message at least once and supports multiple readers and writers 
    interacting with the same queue. 
A single queue can be used simultaneously by many distributed application components, with no need for 
    those components to coordinate with one another to share the queue. 
Although most of the time each message will be delivered to your application exactly once, 
    you should design your system to be idempotent

Amazon SQS is engineered to be highly available and to deliver messages reliably and efficiently; 
    however, the service does not guarantee First In, First Out (FIFO) delivery of messages. 
If your system requires that order be preserved, you can place sequencing information in each message 
    so that you can reorder the messages when they are retrieved from the queue.

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/SQS.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Delay-Queues-and-Visibility-Timeouts&quot;&gt;Delay Queues and Visibility Timeouts&lt;a class=&quot;anchor-link&quot; href=&quot;#Delay-Queues-and-Visibility-Timeouts&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Delay Queues allow you to postpone the delivery of new messages in a queue for a specific number of seconds. 
If you create a delay queue, any message that you send to that queue will be invisible to consumers 
    for the duration of the delay period.
Amazon SQS supports up to 12 hours’ maximum visibility timeout.
By default, the message visibility timeout is set to 30 seconds
The default message retention period that can be set in Amazon SQS is four days.
The longest configurable message retention period for Amazon SQS is 14 days.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Queue-and-Message-Identifiers&quot;&gt;Queue and Message Identifiers&lt;a class=&quot;anchor-link&quot; href=&quot;#Queue-and-Message-Identifiers&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Amazon SQS uses three identifiers that you need to be familiar with: queue URLs, message IDs, 
    and receipt handles.
Amazon SQS assigns each message a unique ID that it returns to you in the SendMessage response.
Each time you receive a message from a queue, you receive a receipt handle for that message.

Queue Operations, Unique IDs, and Metadata
Message Attributes
Long Polling
    When your application queries the Amazon SQS queue for messages, it calls the function ReceiveMessage.
        ReceiveMessage will check for the existence of a message in the queue and return immediately, 
        either with or without a message. 
    If your code makes periodic calls to the queue, this pattern is sufficient. 
    With long polling, you send a WaitTimeSeconds argument to ReceiveMessage of up to 20 seconds. 
    If there is no message in the queue, then the call will wait up to WaitTimeSeconds for a message to
        appear before returning.

Dead Letter Queues
Access Control        
    You want to grant another AWS account a particular type of access to your queue.
    You want to grant another AWS account access to your queue for a specific period of time.
    You want to grant another AWS account access to your queue only if the requests come from your 
        Amazon EC2 instances.
    You want to deny another AWS account access to your queue.

    Amazon SQS Access Control allows you to assign policies to queues that grant specific interactions 
        to other accounts without that account having to assume IAM roles from your account.

Tradeoff Message Durability and Latency
    Amazon SQS does not return success to a SendMessage API call until the message is durably stored in 
        Amazon SQS.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Simple-Workflow-Service-(Amazon-SWF)&quot;&gt;Amazon Simple Workflow Service (Amazon SWF)&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Simple-Workflow-Service-(Amazon-SWF)&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon SWF makes it easy to build applications that coordinate work across distributed components. 
In Amazon SWF, a task represents a logical unit of work that is performed by a component of your 
    application. 
Coordinating tasks across the application involves managing inter-task dependencies, scheduling, and
    concurrency in accordance with the logical flow of the application. 
Amazon SWF gives you full control over implementing and coordinating tasks without worrying about
    underlying complexities such as tracking their progress and maintaining their state.

Workflows
    Using Amazon SWF, you can implement distributed, asynchronous applications as workflows. 
    Workflows coordinate and manage the execution of activities that can be run asynchronously across 
        multiple computing devices and that can feature both sequential and parallel processing.
    When designing a workflow, analyze your application to identify its component tasks, which are represented 
        in Amazon SWF as activities. 
    The workflow’s coordination logic determines the order in which activities are executed.

Workflow Domains
    Domains provide a way of scoping Amazon SWF resources within your AWS account.

Workflow History
    The workflow history is a detailed, complete, and consistent record of every event that occurred 
        since the workflow execution started.

Actors
    Amazon SWF consists of a number of different types of programmatic features known as actors. 
    Actors can be workflow starters, deciders, or activity workers. 
    These actors communicate with Amazon SWF through its API. 
    You can develop actors in any programming language.

Tasks
    Amazon SWF provides activity workers and deciders with work assignments, given as one of three 
        types of tasks: activity tasks, AWS Lambda tasks, and decision tasks.

Task Lists
    Task lists provide a way of organizing the various tasks associated with a workflow. 

Long Polling
    Deciders and activity workers communicate with Amazon SWF using long polling&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Simple-Notification-Service-(Amazon-SNS)&quot;&gt;Amazon Simple Notification Service (Amazon SNS)&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Simple-Notification-Service-(Amazon-SNS)&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon SNS follows the publish-subscribe (pub-sub) messaging paradigm, with notifications being delivered 
    to clients using a push mechanism that eliminates the need to check periodically (or poll) for 
    new information and updates
You can use Amazon SNS to send Short Message Service (SMS) messages to mobile device users in the United 
    States or to email recipients worldwide.

Common Amazon SNS Scenarios
    Fanout
    Application and System Alerts
    Push Email and Text Messaging
    Mobile Push Notifications&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">HashiCorp</title><link href="https://ankushagarwal87.github.io/continuouslearning/hashicorp/2020/07/12/HashiCorp.html" rel="alternate" type="text/html" title="HashiCorp" /><published>2020-07-12T00:00:00-05:00</published><updated>2020-07-12T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/hashicorp/2020/07/12/HashiCorp</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/hashicorp/2020/07/12/HashiCorp.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-12-HashiCorp.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/continuouslearning/images/copied_from_nb/my_icons/image.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Steps&quot;&gt;Steps&lt;a class=&quot;anchor-link&quot; href=&quot;#Steps&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Options
    CLI Command
    API call
    Web UI

Step 1: Configure Transit Secrets Engine
Step 2: Encrypt Secrets
Step 3: Decrypt ciphertext
Step 4: Rotate the Encryption Key
Step 5: Update Key Configuration
Step 6: Generate Data Key
    Can call API to get encypted key &amp;amp; decrypt the file (no need of sending entire file)

Vault HTTP API imposes a maximum request size of 32MB to prevent a denial of service attack. 
This can be tuned per listener block in the Vault server configuration.


Question
    Why don't have own method of encryption/decryption rather then on service
    How hashicorp validate user (who is asking for key or encrypt/decrypt request)
        https://www.youtube.com/watch?v=lZnrrGxrInk&amp;amp;feature=emb_rel_end
    Do we really need to encrypt data when there is option of delete post processing
    If two files comes at the same time - How ABC will work
    Is single instance work on API/File Integration
    Can we not have FTP connector in the end to send file
        Output Port need to be open 
    Email Connector


Reference
    https://learn.hashicorp.com/vault/encryption-as-a-service/eaas-transit
    https://www.vaultproject.io/api-docs/secret/transit
    https://www.hashicorp.com/blog/how-vault-encrypts-application-data-during-transit-and-at-rest/
    https://www.hashicorp.com/resources/encryption-as-a-service-with-vault-s-transit-secret-engine/


Options
    We can have lambda function trigger when file comes to S3 
    Lambda function will dcrypt &amp;amp; again save to S3 
    Trigger ABC on S3


AWS Integration
    https://www.vaultproject.io/docs/auth/aws
    https://www.vaultproject.io/api/auth/aws
    IAM auth method
        The AWS STS API includes a method, sts:GetCallerIdentity, which allows you to validate the identity 
        of a client. The client signs a GetCallerIdentity query using the AWS Signature v4 algorithm 
        and sends it to the Vault server. The credentials used to sign the GetCallerIdentity request 
        can come from the EC2 instance metadata service for an EC2 instance, or from the AWS environment
        variables in an AWS Lambda function execution, which obviates the need for an operator to manually
        provision some sort of identity material first. However, the credentials can, in principle, come 
        from anywhere, not just from the locations AWS has provided for you.

        AWS Security Token Service (AWS STS) is a web service that enables you to request temporary, 
        limited-privilege credentials for AWS Identity and Access Management (IAM) users

        GetCallerIdentity
            Returns details about the IAM user or role whose credentials are used to call the operation. 
            https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html

    EC2 auth method
        Amazon EC2 instances have access to metadata which describes the instance. 
        The Vault EC2 auth method leverages the components of this metadata to authenticate and 
            distribute an initial Vault token to an EC2 instance.

ABC
    An enterprise-level FTP Client is included in the Core edition, which provides an intuitive
    browser-based administrator, extensive security features, user management, file triggers, and 
    detailed audit trails.

Lambda
    https://docs.aws.amazon.com/lambda/latest/dg/with-s3.html&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">Databases and AWS</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/databases/2020/07/11/Databases-and-AWS.html" rel="alternate" type="text/html" title="Databases and AWS" /><published>2020-07-11T00:00:00-05:00</published><updated>2020-07-11T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/databases/2020/07/11/Databases-and-AWS</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/databases/2020/07/11/Databases-and-AWS.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-11-Databases and AWS.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon RDS provides support for six popular relational database engines: 
    MySQL, Oracle, PostgreSQL, Microsoft SQL Server, MariaDB, and Amazon Aurora
Amazon Redshift is a high-performance data warehouse designed specifically for OLAP use cases.
Traditional relational databases are difficult to scale beyond a single server without significant 
    engineering and cost, but a NoSQL architecture allows for horizontal scalability on commodity hardware.
Amazon RDS makes it easy to replicate your data to increase availability, improve durability, or scale 
    up or beyond a single database instance for read-heavy database workloads.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;RDS&quot;&gt;RDS&lt;a class=&quot;anchor-link&quot; href=&quot;#RDS&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon RDS MySQL,PostgreSQL,MariaDB,Oracle,Microsoft SQL Server supports Multi-AZ deployments for 
    high availability and read replicas for horizontal scaling
Amazon Aurora can deliver up to five times the performance of MySQL without requiring changes to most 
    of your existing web applications. 
An Amazon Aurora DB cluster consists of two different types of instances:
    Primary Instance 
        This is the main instance, which supports both read and write workloads. 
        When you modify your data, you are modifying the primary instance. 
        Each Amazon Aurora DB cluster has one primary instance.
    Amazon Aurora Replica 
        This is a secondary instance that supports only read operations. 
        Each DB cluster can have up to 15 Amazon Aurora Replicas in addition to the primary instance.
        By using multiple Amazon Aurora Replicas, you can distribute the read workload among various 
            instances, increasing performance. 
        You can also locate your Amazon Aurora Replicas in multiple Availability Zones to increase 
            your database availability.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Storage-Options&quot;&gt;Storage Options&lt;a class=&quot;anchor-link&quot; href=&quot;#Storage-Options&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Amazon RDS is built using Amazon Elastic Block Store (Amazon EBS) and allows you to select the right 
    storage option based on your performance and cost requirements. 
Depending on the database engine and workload, you can scale up to 4 to 6TB in provisioned storage 
    and up to 30,000 IOPS. 
Amazon RDS supports three storage types: Magnetic, General Purpose (Solid State Drive [SSD]), 
    and Provisioned IOPS (SSD)

Magnetic Magnetic storage, also called standard storage, offers cost-effective storage that is ideal 
    for applications with light I/O requirements.
General Purpose (SSD) General purpose (SSD)-backed storage, also called gp2, can provide faster access 
    than magnetic storage. This storage type can provide burst performance to meet spikes and is excellent 
    for small- to medium-sized databases.
Provisioned IOPS (SSD) Provisioned IOPS (SSD) storage is designed to meet the needs of I/O-intensive 
    workloads, particularly database workloads, that are sensitive to storage performance and consistency 
    in random access I/O throughput.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Backup-and-Recovery&quot;&gt;Backup and Recovery&lt;a class=&quot;anchor-link&quot; href=&quot;#Backup-and-Recovery&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;RPO is defined as the maximum period of data loss that is acceptable in the event of a failure or incident
RTO is defined as the maximum amount of downtime that is permitted to recover from backup and to 
    resume processing

Automated Backups
    An automated backup is an Amazon RDS feature that continuously tracks changes and backs up your database
    One day of backups will be retained by default, but you can modify the retention period up to a 
        maximum of 35 days
Manual DB Snapshots
    In addition to automated backups, you can perform manual DB snapshots at any time. 
    Unlike automated snapshots that are deleted after the retention period, manual DB snapshots are 
        kept until you explicitly delete them with the Amazon RDS console or the DeleteDBSnapshot action.
    You cannot restore from a DB snapshot to an existing DB Instance; a new DB Instance is created when 
        you restore. 
    When you restore a DB Instance, only the default DB parameter and security groups are associated 
        with the restored instance. &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;High-Availability-with-Multi-AZ&quot;&gt;High Availability with Multi-AZ&lt;a class=&quot;anchor-link&quot; href=&quot;#High-Availability-with-Multi-AZ&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Multi-AZ allows you to place a secondary copy of your database in another Availability Zone for 
    disaster recovery purposes
Amazon RDS automatically replicates the data from the master database or primary instance to the 
    slave database or secondary instance using synchronous replication.
To improve database performance using multiple DB Instances, use read replicas or other DB caching 
    technologies such as Amazon ElastiCache.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Scaling-Up-and-Out&quot;&gt;Scaling Up and Out&lt;a class=&quot;anchor-link&quot; href=&quot;#Scaling-Up-and-Out&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Vertical Scalability
    Storage expansion is supported for all of the database engines except for SQL Server.
Horizontal Scalability with Partitioning
    A relational database can be scaled vertically only so much before you reach the maximum instance size.
    Partitioning a large relational database into multiple instances or shards is a common technique 
        for handling more requests beyond the capabilities of a single instance.
    The application needs to decide how to route database requests to the correct shard and becomes 
        limited in the types of queries that can be performed across server boundaries.
    NoSQL databases like Amazon DynamoDB or Cassandra are designed to scale horizontally.
Horizontal Scalability with Read Replicas
    Another important scaling technique is to use read replicas to offload read transactions from the 
        primary database and increase the overall number of transactions
    Read replicas are currently supported in Amazon RDS for MySQL, PostgreSQL, MariaDB and Amazon Aurora&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Security&quot;&gt;Security&lt;a class=&quot;anchor-link&quot; href=&quot;#Security&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Protect access to your infrastructure resources using AWS Identity and Access Management (IAM) policies 
    that limit which actions AWS administrators can perform
Another security best practice is to deploy your Amazon RDS DB Instances into a private subnet within 
    an Amazon Virtual Private Cloud (Amazon VPC) that limits network access to the DB Instance. 
Restrict network access using network Access Control Lists (ACLs) and security groups to limit inbound 
    traffic to a short list of source IP addresses.
At the database level, you will also need to create users and grant them permissions to read and write 
    to your databases. 
Access to the database is controlled using the database engine-specific access control and user 
    management mechanisms
Finally, protect the confidentiality of your data in transit and at rest with multiple encryption 
    capabilities provided with Amazon RDS.
You can securely connect a client to a running DB Instance using Secure Sockets Layer (SSL) to protect 
    data in transit. 
Encryption at rest is possible for all engines using the Amazon Key Management Service (KMS) or 
    Transparent Data Encryption (TDE). 
All logs, backups, and snapshots are encrypted for an encrypted Amazon RDS instance.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-Redshift&quot;&gt;Amazon Redshift&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-Redshift&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Amazon Redshift is a fast, powerful, fully managed, petabyte-scale data warehouse service in the cloud. 
Amazon Redshift is a relational database designed for OLAP scenarios and optimized for high-performance
    analysis and reporting of very large datasets. 
Amazon Redshift is based on industry-standard PostgreSQL, so most existing SQL client applications 
    will work with only minimal changes.
The key component of an Amazon Redshift data warehouse is a cluster. 
A cluster is composed of a leader node and one or more compute nodes. 
The client application interacts directly only with the leader node, and the compute nodes are transparent 
    to external applications.
The six node types are grouped into two categories: Dense Compute and Dense Storage. 
The Dense Compute node types support clusters up to 326TB using fast SSDs, while the Dense Storage 
    nodes support clusters up to 2PB using large magnetic disks
When you submit a query, Amazon Redshift distributes and executes the query in parallel across all of 
    a cluster’s compute nodes. 
Amazon Redshift also spreads your table data across all compute nodes in a cluster based on a 
    distribution strategy that you specify

Table Design
    Data Types
    Compression Encoding
    Distribution Strategy
        EVEN distribution  
            This is the default option and results in the data being distributed across the slices 
                in a uniform fashion regardless of the data.
        KEY distribution  
            With KEY distribution, the rows are distributed according to the values in one column. 
            The leader node will store matching values close together and increase query performance 
                for joins.
        ALL distribution  
            With ALL, a full copy of the entire table is distributed to every node. 
            This is useful for lookup tables and other large tables that are not updated frequently.
    Sort Keys

Loading Data
     COPY
Querying Data
Snapshots
Security&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Amazon-DynamoDB&quot;&gt;Amazon DynamoDB&lt;a class=&quot;anchor-link&quot; href=&quot;#Amazon-DynamoDB&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;To help maintain consistent, fast performance levels, all table data is stored on high-performance 
    SSD disk drives. 
Performance metrics, including transactions rates, can be monitored using Amazon CloudWatch.
In addition to providing high-performance levels, Amazon DynamoDB also provides automatic high-availability 
    and durability protections by replicating data across multiple Availability Zones within an AWS Region.
DynamoDB provides a web service API that accepts requests in JSON format.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Data-Types&quot;&gt;Data Types&lt;a class=&quot;anchor-link&quot; href=&quot;#Data-Types&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Scalar Data Types 
    A scalar type represents exactly one value. 
    Amazon DynamoDB supports the following five scalar types:
        String Text and variable length characters up to 400KB. Supports Unicode with UTF8 encoding
        Number Positive or negative number with up to 38 digits of precision
        Binary Binary data, images, compressed objects up to 400KB in size
        Boolean Binary flag representing a true or false value
        Null Represents a blank, empty, or unknown state. String, Number, Binary, Boolean cannot be empty.

Set Data Types 
    Sets are useful to represent a unique list of one or more scalar values. 
    Each value in a set needs to be unique and must be the same data type. 
    Sets do not guarantee order. 
    Amazon DynamoDB supports three set types: String Set, Number Set, and Binary Set.
        String Set Unique list of String attributes
        Number Set Unique list of Number attributes
        Binary Set Unique list of Binary attributes

Document Data Types 
    Document type is useful to represent multiple nested attributes, similar to the structure of a JSON file
    Amazon DynamoDB supports two document types: List and Map. 
    Multiple Lists and Maps can be combined and nested to create complex structures.
        List Each List can be used to store an ordered list of attributes of different data types.
        Map Each Map can be used to store an unordered list of key/value pairs. &lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Primary-Key&quot;&gt;Primary Key&lt;a class=&quot;anchor-link&quot; href=&quot;#Primary-Key&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;When you create a table, you must specify the primary key of the table in addition to the table name. 
Amazon DynamoDB supports two types of primary keys, and this configuration cannot be changed after a 
    table has been created:

    Partition Key 
        The primary key is made of one attribute, a partition (or hash) key. 
        Amazon DynamoDB builds an unordered hash index on this primary key attribute.
    Partition and Sort Key 
        The primary key is made of two attributes. 
        The first attribute is the partition key and the second one is the sort (or range) key. 
        Each item in the table is uniquely identified by the combination of its partition and sort key value
        It is possible for two items to have the same partition key value, but those two items must 
            have different sort key values.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Provisioned-Capacity&quot;&gt;Provisioned Capacity&lt;a class=&quot;anchor-link&quot; href=&quot;#Provisioned-Capacity&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;When you create an Amazon DynamoDB table, you are required to provision a certain amount of read and 
    write capacity to handle your expected workloads. 
Based on your configuration settings, DynamoDB will then provision the right amount of infrastructure
    capacity to meet your requirements with sustained, low-latency response times&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Secondary-Indexes&quot;&gt;Secondary Indexes&lt;a class=&quot;anchor-link&quot; href=&quot;#Secondary-Indexes&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;When you create a table with a partition and sort key (formerly known as a hash and range key), you can
    optionally define one or more secondary indexes on that table. 
A secondary index lets you query the data in the table using an alternate key, in addition to queries
    against the primary key. 

Amazon DynamoDB supports two different kinds of indexes:
    Global Secondary Index 
        The global secondary index is an index with a partition and sort key that can be different 
            from those on the table. 
        You can create or delete a global secondary index on a table at any time.
    Local Secondary Index 
        The local secondary index is an index that has the same partition key attribute as the primary key 
            of the table, but a different sort key. 
        You can only create a local secondary index when you create a table.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Writing-and-Reading-Data&quot;&gt;Writing and Reading Data&lt;a class=&quot;anchor-link&quot; href=&quot;#Writing-and-Reading-Data&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Writing Items
    Amazon DynamoDB provides three primary API actions to create, update, and delete items: 
        PutItem, UpdateItem, and DeleteItem
Reading Items
    After an item has been created, it can be retrieved through a direct lookup by calling the 
        GetItem action or through a search using the Query or Scan action&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry><entry><title type="html">AWS Identity and Access Management (IAM)</title><link href="https://ankushagarwal87.github.io/continuouslearning/aws/iam/2020/07/08/AWS-Identity-and-Access-Management-(IAM).html" rel="alternate" type="text/html" title="AWS Identity and Access Management (IAM)" /><published>2020-07-08T00:00:00-05:00</published><updated>2020-07-08T00:00:00-05:00</updated><id>https://ankushagarwal87.github.io/continuouslearning/aws/iam/2020/07/08/AWS-Identity-and-Access-Management-(IAM)</id><content type="html" xml:base="https://ankushagarwal87.github.io/continuouslearning/aws/iam/2020/07/08/AWS-Identity-and-Access-Management-(IAM).html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-08-AWS Identity and Access Management (IAM).ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Introduction&quot;&gt;Introduction&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;IAM uses traditional identity concepts such as users, groups, and access control policies to control who 
    can use your AWS account, what services and resources they can use, and how they can use them. 
The control provided by IAM is granular enough to limit a single user to the ability to perform a single 
    action on a specific resource from a specific IP address during a specific time window. 
Applications can be granted access to AWS resources whether they are running on-premises or in the cloud. 

If your application identities are based on Active Directory, your on-premises Active Directory can be 
    extended into the cloud to continue to fill that need. 
A great solution for using Active Directory in the cloud is AWS Directory Service, which is an Active
    Directory-compatible directory service that can work on its own or integrate with your on-premises 
    Active Directory. 
Finally, if you are working with a mobile app, consider Amazon Cognito for identity management for 
    mobile applications.

Operating System Access - Active Directory LDAP Machine-specific accounts
Application Access - Active Directory, Application User Repositories, Amazon Cognito
AWS Resources - IAM

IAM is controlled like most other AWS Cloud services:
    AWS Management Console
    CLI
    AWS SDK&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Principals&quot;&gt;Principals&lt;a class=&quot;anchor-link&quot; href=&quot;#Principals&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;The first IAM concept to understand is principals. 
A principal is an IAM entity that is allowed to interact with AWS resources. 
A principal can be permanent or temporary, and it can represent a human or an application. 
There are three types of principals: root users, IAM users, and roles/temporary security tokens.

Root User
    When you first create an AWS account, you begin with only a single sign-in principal that has complete
        access to all AWS Cloud services and resources in the account. 
    This principal is called the root user. As long as you have an open account with AWS, the root user 
        for that relationship will persist. 
    The root user can be used for both console and programmatic access to AWS resources.

IAM Users
    Users are persistent identities set up through the IAM service to represent individual people 
        or applications. 
    You may create separate IAM users for each member of your operations team so they can interact 
        with the console and use the CLI.

Roles/Temporary Security Tokens
    Roles are used to grant specific privileges to specific actors for a set duration of time. 
    These actors can be authenticated by AWS or some trusted external system. 
    When one of these actors assumes a role, AWS provides the actor with a temporary security token 
        from the AWS Security Token Service (STS) that the actor can use to access AWS Cloud services. 

    Amazon EC2 Roles—Granting permissions to applications running on an Amazon EC2 instance.
    Cross-Account Access—Granting permissions to users from other AWS accounts, whether you 
        control those accounts or not.
    Federation—Granting permissions to users authenticated by a trusted external system.

    Amazon EC2 Roles
        Suppose that an application running on an Amazon EC2 instance needs to access an Amazon Simple 
            Storage Service (Amazon S3) bucket. 
        A policy granting permission to read and write that bucket can be created and assigned to an IAM 
            user,and the application can use the access key for that IAM user to access the Amazon S3 bucket
        The problem with this approach is that the access key for the user must be accessible to the
            application, probably by storing it in some sort of configuration file. 

        An alternative is to create an IAM role that grants the required access to the Amazon S3 bucket. 
        When the Amazon EC2 instance is launched, the role is assigned to the instance. 
        When the application running on the instance uses the Application Programming Interface (API) to 
            access the Amazon S3 bucket, it assumes the role assigned to the instance and obtains a 
            temporary token that it sends to the API. 

    Cross-Account Access
        Another common use case for IAM roles is to grant access to AWS resources to IAM users in other 
            AWS accounts

    Federation
        Many organizations already have an identity repository outside of AWS and would rather leverage 
            that repository than create a new and largely duplicate repository of IAM users. 
        Similarly, web-based applications may want to leverage web-based identities such as Facebook, 
            Google, or Login with Amazon. 
        IAM Identity Providers provide the ability to federate these outside identities with IAM and 
            assign privileges to those users authenticated outside of IAM.
        IAM can integrate with two different types of outside Identity Providers (IdP). 
        For federating web identities such as Facebook, Google, or Login with Amazon, IAM supports 
            integration via OpenID Connect (OIDC).
        For federating internal identities, such as Active Directory or LDAP, IAM supports integration 
            via Security Assertion Markup Language 2.0 (SAML). 
        A SAML-compliant IdP such as Active Directory Federation Services (ADFS) is used to federate the
            internal directory to IAM. 
        In each case, federation works by returning a temporary token associated with a role to the IdP 
            for the authenticated identity to use for calls to the AWS API.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Authentication&quot;&gt;Authentication&lt;a class=&quot;anchor-link&quot; href=&quot;#Authentication&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;There are three ways that IAM authenticates a principal:
User Name/Password
    When a principal represents a human interacting with the console, the human will provide a user
        name/password pair to verify their identity. 
    IAM allows you to create a password policy enforcing password complexity and expiration.

Access Key
    An access key is a combination of an access key ID (20 characters) and an access secret key (40
        characters). When a program is manipulating the AWS infrastructure via the API, it will use 
        these values to sign the underlying REST calls to the services. 

Access Key/Session Token
    When a process operates under an assumed role, the temporary security token provides an access key 
        for authentication. In addition to the access key (remember that it consists of two parts), 
        the token also includes a session token. 
     Calls to AWS must include both the two-part access key and the session token to authenticate.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Authorization&quot;&gt;Authorization&lt;a class=&quot;anchor-link&quot; href=&quot;#Authorization&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;After IAM has authenticated a principal, it must then manage the access of that principal to protect your 
    AWS infrastructure. 
The process of specifying exactly what actions a principal can and cannot perform is called authorization.
Authorization is handled in IAM by defining specific privileges in policies and associating those policies 
    with principals.

Policies
    A policy is a JSON document that fully defines a set of permissions to access and manipulate 
        AWS resources. Policy documents contain one or more permissions, with each permission defining

    Effect
        A single word: Allow or Deny.

    Service
        For what service does this permission apply? Most AWS Cloud services support granting access 
            through IAM, including IAM itself.

    Resource
        The resource value specifies the specific AWS infrastructure for which this permission applies. 
        This is specified as an Amazon Resource Name (ARN). 
        The format for an ARN varies slightly between services, but the basic format is:
        &quot;arn:aws:service:region:account-id:[resourcetype:]resource&quot;

    Action
        The action value specifies the subset of actions within a service that the permission allows
            or denies. For instance, a permission may grant access to any read-based action for Amazon S3.
        A set of actions can be specified with an enumerated list or by using wildcards (Read*).

    Condition
        The condition value optionally defines one or more additional restrictions that limit the actions
            allowed by the permission. 
        For instance, the permission might contain a condition that limits the ability to access a 
            resource to calls that come from a specific IP address range. 
        Another condition could restrict the permission only to apply during a specific time interval.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Associating-Policies-with-Principals&quot;&gt;Associating Policies with Principals&lt;a class=&quot;anchor-link&quot; href=&quot;#Associating-Policies-with-Principals&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;There are several ways to associate a policy with an IAM user; this section will only cover the most common.
A policy can be associated directly with an IAM user in one of two ways:
User Policy
    These policies exist only in the context of the user to which they are attached. 
    In the console, a user policy is entered into the user interface on the IAM user page.

Managed Policies
    These policies are created in the Policies tab on the IAM page and exist independently of any 
        individual user. 
    In this way, the same policy can be associated with many users or groups of users. 

There are two ways a policy can be associated with an IAM group:
Group Policy
    These policies exist only in the context of the group to which they are attached. 
    In the AWS Management Console, a group policy is entered into the user interface on the IAM Group page.
Managed Policies
    In the same way that managed policies can be associated with IAM users, they can also be associated 
        with IAM groups.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Other-Key-Features&quot;&gt;Other Key Features&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Key-Features&quot;&gt; &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Multi-Factor Authentication (MFA)
Rotating Keys
    To this end, it is a security best practice to rotate access keys associated with your IAM users.
    IAM facilitates this process by allowing two active access keys at a time. 
    The process to rotate keys can be conducted via the console, CLI, or SDKs:            
        Create a new access key for the user.
        Reconfigure all applications to use the new access key.
        Disable the original access key 
        Verify the operation of all applications.
        Delete the original access key.
Resolving Multiple Permissions        
    Initially the request is denied by default.
    All the appropriate policies are evaluated; if there is an explicit “deny” found in any policy, 
        the request is denied and evaluation stops.
    If no explicit “deny” is found and an explicit “allow” is found in any policy, the request is allowed.
    If there are no explicit “allow” or “deny” permissions found, then the default “deny” is 
        maintained and the request is denied.&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Ankush Agarwal</name></author><summary type="html"></summary></entry></feed>